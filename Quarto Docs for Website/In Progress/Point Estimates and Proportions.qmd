---
title: "Point Estimates"
author: "James Van Slyke"
---

```{r}
#| include: false
#Libraries
library(tidyverse)
library(fivethirtyeight)
```

Reference -

Diez, D., OpenIntro Statistics

Chapter 5 - Foundations for Inference

## Polling and Point estimates

One poll that is tracked often is the presidential approval ratings. Different polling agencies will conduct polls throughout the year to measure the country's assessment of how well the current president is doing running the country. Polling companies use samples to estimate presidential approval ratings, it would be next to impossible to poll the entire country every couple of weeks to determine the current approval ratings.

Since we need to use samples to estimate the true current approval rating in the United States, the approval rating obtained from the sample is known as the *point estimate.* It's an estimate of the US population referred to as the *parameter of interest*. A *parameter* is a numeric value related to a population. Statistics attempts to quantify how well the parameter estimate *estimates* the parameter of interest. This is possible because there are certain properties that are usually present between a population and samples drawn from that population.

## A stimulated approval rating

One of the great things that using R allows us to do is different types of simulations. We can simulate the behaviors and properties of a fictional population. For example, let's say that the current approval rating for a president is 60% approve and 40% disapprove. Thinking about this in terms of proportions .60 approve and .40 disapprove. So the true approval rating of the president in the population of US citizens would be 60%. Let's simulate this:

```{r}
#Create a population of 340 million

pop_size <- 340000000
#Create the approval/disapproval ratings
possible_entries <- c(rep("approve", 0.60 * pop_size),
                      rep("disapprove", 0.40 * pop_size))
```

Then we can take a random sample from this population

```{r}
#Keep randomized sample the same
set.seed(123)

#Randomly Sample 1000 from the population
sampled_entries <- sample(possible_entries, size = 1000)
```

The random sample can be used to estimate the true population proportion. This is referred to as *p-hat* and the symbol looks like this $\hat{p}$. This p-hat is our point estimate of the true approval rating in the population, even though in this case we know the real parameter.

```{r}
sum(sampled_entries == "approve")/1000
```

Notice that this sample gave us an approval proportion of 0.611 or $\hat{p}=0.611$ or 61%. The difference between the true parameter 60% and the p-hat is 1%. This is called the *error* of the estimate. As discussed throughout the course, all measurement and sampling involves a certain amount of error, but that error can be quantified to determine how confident we can be in our numbers.

### Multiple Samples

Let's look to see how our p-hat changes over several samples

Sample 2

```{r}
#Sample
sampled_entries <- sample(possible_entries, size = 1000)

#p-hat
sum(sampled_entries == "approve")/1000
```

Sample 3

```{r}
#Sample
sampled_entries <- sample(possible_entries, size = 1000)

#p-hat
sum(sampled_entries == "approve")/1000
```

Sample 4

```{r}
#Sample
sampled_entries <- sample(possible_entries, size = 1000)

#p-hat
sum(sampled_entries == "approve")/1000
```

Notice how $\hat{p}$ varies slightly with every sample taken. This demonstrates the sampling error that exists between a sample and the population it is trying to estimate.

### Larger numbers of samples

We can actually do better than just a few random samples from a population. Let's investigate what happens when we take a large number of samples and calculate the p-hat for each of the samples.

To do this, we can use the binomial distribution we used in an earlier lesson. Remember that a binomial distribution is used when there are two possibilities for a particular outcome. In this case the two outcomes are *approve* or *disapprove*. In this case we can use rbinom to randomly create a histogram based on sampling from a population with 60% approval and 40% disapproval.

```{r}
#Set the Parameters
n_samples <- 10000   # Number of samples
sample_size <- 1000  # Size of each sample
true_p <- 0.6        # True proportion of "approve"

#Use a randomly generated binomial distribution to simulate taking 10,000 samples with an n = 1000 from the population of the US
sample_counts <- rbinom(n = n_samples, size = sample_size, prob = true_p)

# Calculate the p-hat from the samples
p_hats <- sample_counts / sample_size

# Create a datafrome of the p-hats
p_hat_df <- data.frame(p_hat = p_hats)

# Create histogram
phat_hist <- ggplot(p_hat_df, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.005, fill = "skyblue", color = "black") +
  labs(title = "Sampling Distribution of p̂",
       x = "Sample Proportion (p̂)",
       y = "Frequency") +
  theme_minimal()
phat_hist
```

What does this graph remind you of? Hopefully you've noticed that it looks like a normal curve. In terms of probability, remember that the most likely outcome for a given distribution is the center or middle of the distribution, in this case the mean. The center of the distribution of sampled *approval* ratings matches the population parameter at 60%. This is no accident. It is part of one of the basic aspects of inferential statistics, *the central limit theorem*. The first part of the central limit theory looks like this:

> The proportion found in the population will be equal to the proportion found in sampling distribution, given that the sample is sufficiently large

Or

$$
\mu_{\hat{p}} = p
$$

The second part of the central limit theorem has to do with the standard deviation of the sampling distribution of *p*, which in this case we call it the standard error. Since we sampled from the population and created a distribution of p-hat estimates of the population proportion, the standard error will indicate the spread of that p-hat point estimate. Here is the formula:

$$
SE_{\hat{p}} = \sqrt{\frac{p(1 - p)}{n}}
$$
