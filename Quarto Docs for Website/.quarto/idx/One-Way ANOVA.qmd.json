{"title":"One-Way ANOVA","markdown":{"yaml":{"title":"One-Way ANOVA","format":"html","author":"James Van Slyke"},"headingText":"One-Way ANOVA","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nch15ds1 <- read.csv(\"ch15ds1.csv\")\nlibrary(sjPlot)\n```\n\n\nANOVA stands for analysis of variance, which is based on the *F* statistic, which is named after the statistician who invented it, R. A. Fisher. The statistic is fundamentally the ratio of two independent variance estimates of the same population variance (Pagano, 2013). Thus the basic formula is:\n\n$$\nF = \\frac{variance\\;estimate\\; 1\\; of\\; \\sigma^{2}}{variance\\; estimate\\; 2\\; of\\; \\sigma^{2}}\n$$\n\n## How Many Groups?\n\nUltimately the *F* test or ANOVA is used to analyze differences in the means of more than two groups. Remember we use the *t* test to analyze differences in the means of two groups, but when we have more than two groups we need a different test. In this case, we use the *ANOVA*.\n\n## Null and Alternative Hypotheses\n\nHere are the basic assumptions of the two hypotheses used in an ANOVA.\n\nNull $$\nH_0 : \\mu_1=\\mu_2=\\mu_3\n$$ Alternative $$\nH_1 : \\mu_1\\neq\\mu_2\\neq\\mu_3\n$$\n\n## \n\nSo the Null hypothesis assumes there will be no differences between the means or that the groups come from the same population, while the alternative assumes there is a difference between the means or the groups come from different populations. One thing to remember, the ANOVA test can only identify if *some* of the group means are different. It cannot identify which means are different. So the means for group 1 and 2 may be statistically the same, while the means for group 2 and 3 may be different, but the ANOVA test will still be significant.\n\n## Signal vs. Noise\n\nRemember our basic formula for statistics.\n\n$$\nStatistics = \\frac{Signal}{Noise}\n$$\n\n*Signal* refers to systematic variation or variation based on the causal work of the independent variable. Whereas *noise* refers to unsystematic variation or variation which is not the result of the independent variable. Unsystematic variation is the result of measurement error and we've seen that measurement error occurs in all types of measurement and statistics.\n\n## \n\nSo the changes observed in our dataset that are the result of systematic variation have to be *larger* then the differences we observe as the result of unsystematic variation for our statistical finding to be considered significant.\n\n## \n\nRemember that the null hypothesis assumes no differences between the groups, whereas the alternative hypothesis assumes the groups will be different because of the manipulation of the independent variable.\n\n## Levels of the Independent variable\n\nANOVA enables the comparison of more than two groups, which is often structured to analyze different levels of an independent variable. By levels we are referring to different amounts or quantities of the independent variable. For example, one group may be the control group, but then subsequent groups may have different quantities of the independent variable.\n\nHere is the dataset\n\n```{r, eval=TRUE}\nch15ds1\n```\n\nFirst let's look at the independent variable, which is attendance at preschool.\n\nIV = Preschool\n\nHere it is in R studio labeled as \"Group\"\n\n```{r}\nch15ds1$Group\n```\n\nNotice that there is 3 levels to this independent variable based on the amount of time spent in preschool per week: 5 hours, 10 hours, and 20 hours. Notice that there is no control group. Everyone is in preschool. So the hypothesis is really whether *more* time in preschool increases language development.\n\n### Creating Factors\n\nAn important first step for data analysis is to make sure the variables are in the correct format. We can use the `str` command to figure out the types of variables in the dataset.\n\n```{r}\nstr(ch15ds1)\n```\n\nLanguage.Score is an integer `int` or whole number, which makes sense for a measurement scale that is looking at language development.\n\nGroup is a character `chr`, which is fine for defining groups, but we would prefer it to be a factor so it could more easily distinguish the levels of the independent variable.\n\nSo let's change the variable type for group to a factor.\n\n```{r}\nch15ds1$Group <- factor(ch15ds1$Group, \n    levels = c(\"5 Hours\", \"10 Hours\", \"20 Hours\"))\n```\n\nAnd then check it\n\n```{r}\nstr(ch15ds1$Group)\n```\n\n### Are the means different?\n\nThe first question for the dataset is whether the means are different. More specifically, the mean level of language development should *increase* with an increase in hours spent at preschool.\n\n#### Mean difference between the groups\n\n```{r}\nch15ds1 |> \n  group_by(Group) |> \n  summarise(n = n(),\n            mean = mean(Language.Score))\n```\n\nSo the means are different and the language score increases with hours spent in preschool. Now it needs to be determined if the differences between the means are statistically significant. This is where we need the *ANOVA* or *F* Test.\n\n## Review\n\nRemember that the F test or ANOVA is based on comparing variation between the groups (signal) to variation within the groups (noise). So the equation is:\n\n$$\nF = \\frac{MS_{between}}{MS_{within}}\n$$\n\nHowever, there are some different steps we need to take to get to the two types of Mean Squares $MS$ for this formula.\n\nFor this usage of the ANOVA, the *total variability* $SS_T$ is partitioned (divided or separated) into 2 groups or sources. The variability between the groups $SS_{between}$ and the variability within the groups $SS_{within}$. Remember that variability between groups gives us evidence that the groups are different and if the variability is greater than the variability within the groups than our F value will be significant.\n\nHowever, the two sum of squares values ($SS_{within}$ & $SS_{between}$) need to be averaged based on the number of scores from which they were calculated in order to eliminate bias. In this case we'll use the degrees of freedom to accomplish this task $df$. Here is the formulas:\n\n$$df_{within} = N - 1$$\n\n$$df_{between}=k-1$$\n\n$N$ stands for the number of observations or participants we have in all the groups because it deals with individual variation. $k$ stands for the number of groups we have because it deals with group variation. Here is an overview of the entire formula.\n\n$$\n\\frac{SS_{between}/df_{between}}{SS_{within}/df_{within}} = \\frac{MS_{between}}{MS_{within}}= F\n$$\n\n### *F* Distribution\n\nHere's a look at the *F* distribution. Notice both the similaries and differences to the binomial and *t* and *z* distributions.\n\n```{r}\ndist_f(deg.f1 = 4, deg.f2 = 20, p = .05)\n```\n\nThe *F* distribution is also a family of curves based on the degrees of freedom. Notice that the distribution has a positive skew (more scores at the lower end of the distribution) and it also only had one tail rather than two tails. This is another indication that the *F* test can't determine the direction of difference between the groups, only if there is a difference between the groups.\n\n## Using R Studio to calculate the ANOVA\n\nIn another section, ANOVA was used to test a linear regression model. For that model a comparison was made between the improvement of the linear model in comparison to the grand mean $SS_{M}$ and the measurement error based on the residuals $SS_{R}$. There is a strong statistical relationship between regression and ANOVA and in fact ANOVA for groups can be understood as a part of the general linear model (GLM). The differences between the groups $SS_{between}$ can be understood as a line composed of the group means and compared to the grand mean $SS_M$. The greater the difference between this line and the grand mean, the greater the difference between the group means. $SS_{within}$ can be understood as the residuals for each observation and the grand mean $SS_R$. Everything else remains the same ($df$, $MS$, and $F$) when running the ANOVA in R Studio.\n\n#### Running the Code\n\nHere's the basic set up for running ANOVA\n\nObject \\<- aov(Dependent Variable \\~ Independent Variable, data = your dataset)\n\nSo in this case\n\n```{r}\nANOVA_1 <- aov(Language.Score~Group, data = ch15ds1)\n```\n\nFor ANOVA, the results are saved in an object, so we need to use `summary` to get the results.\n\n```{r}\nsummary(ANOVA_1)\n```\n\n\"Group\" is the independent variable so Sum Sq stands for the $SS_{between}$ or $SS_M$, whereas \"Residuals stands for the $SS_{within}$ or $SS_R$.\n\nThe *F* value is 8.799 and the significance or *p* value is 0.00114, so the results are significant.\n\n### Bar Graph of the Data\n\nStep 1 - create table of Descriptive Statistics\n\n```{r, eval=TRUE}\nlibrary(dplyr)\nPreschool_Descriptives <- ch15ds1 %>%\n  group_by(Group) %>%\n  summarize(n = n(),\n            mean = mean(Language.Score),\n            sd = sd(Language.Score),\n            se = sd / sqrt(n),\n            ci = qt(0.975, df = n - 1) * sd / sqrt(n))\n```\n\nCheck it out\n\n```{r, eval=TRUE}\nPreschool_Descriptives\n```\n\nNow graph it based on the descriptive statistics\n\n```{r, eval=TRUE}\nggplot(Preschool_Descriptives, \n       aes(x = Group, \n           y = mean)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin=mean-ci,\n                    ymax=mean+ci))\n```\n\nMake the graph look better.\n\n```{r}\nggplot(Preschool_Descriptives, \n       aes(x = Group,\n           y = mean)) +\n  theme_minimal() +\n  geom_bar(stat = \"identity\", fill=\"steelblue\") +\n  geom_errorbar(aes(ymin=mean-ci,\n                    ymax=mean+ci), width=.3, size=1) +\n  labs(title = \"Does Preschool Effect Language Development?\", \n       y=\"Mean Score on Language Test\", x=\"Number of Hours Spent in Preschool\") \n\n\n```\n\n### Effect Size\n\nFigure out the effect size - Eta squared The formula is SSbetween/SSTotal or SSbetween/SSbetween+SSResidual\n\n```{r, eval=TRUE}\n1133/(1133+1738)\n```\n\n### Conclusion\n\nWrite out conclusion\n\n> Number of hours in Preschool had a significant effect on language development, F(2, 27) = 8.799, p = 0.00114, 𝜂2 = 0.39.\n\nWhere is the difference? Need to use post hoc tests\n\n### TukeyHSD\n\nTukeyHSD will tell us where the differences are between the individual groups.\n\nRun TukeyHSD on saved ANOVA results\n\n```{r}\nTukeyHSD(ANOVA_1)\n```\n\nFinally, write out the whole conclusion.\n\n> TukeyHSD post hoc tests revealed that 20 hours a week of preschool (M=91.6, SE=1.96) resulted in significantly higher levels of language development in comparison to 5 hours (M=76.6, SE=3.78). This difference, -15 95% CI\\[-23.90, -6.10\\] was significant with an adjusted p = .0008.\n\n### \n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nch15ds1 <- read.csv(\"ch15ds1.csv\")\nlibrary(sjPlot)\n```\n\n## One-Way ANOVA\n\nANOVA stands for analysis of variance, which is based on the *F* statistic, which is named after the statistician who invented it, R. A. Fisher. The statistic is fundamentally the ratio of two independent variance estimates of the same population variance (Pagano, 2013). Thus the basic formula is:\n\n$$\nF = \\frac{variance\\;estimate\\; 1\\; of\\; \\sigma^{2}}{variance\\; estimate\\; 2\\; of\\; \\sigma^{2}}\n$$\n\n## How Many Groups?\n\nUltimately the *F* test or ANOVA is used to analyze differences in the means of more than two groups. Remember we use the *t* test to analyze differences in the means of two groups, but when we have more than two groups we need a different test. In this case, we use the *ANOVA*.\n\n## Null and Alternative Hypotheses\n\nHere are the basic assumptions of the two hypotheses used in an ANOVA.\n\nNull $$\nH_0 : \\mu_1=\\mu_2=\\mu_3\n$$ Alternative $$\nH_1 : \\mu_1\\neq\\mu_2\\neq\\mu_3\n$$\n\n## \n\nSo the Null hypothesis assumes there will be no differences between the means or that the groups come from the same population, while the alternative assumes there is a difference between the means or the groups come from different populations. One thing to remember, the ANOVA test can only identify if *some* of the group means are different. It cannot identify which means are different. So the means for group 1 and 2 may be statistically the same, while the means for group 2 and 3 may be different, but the ANOVA test will still be significant.\n\n## Signal vs. Noise\n\nRemember our basic formula for statistics.\n\n$$\nStatistics = \\frac{Signal}{Noise}\n$$\n\n*Signal* refers to systematic variation or variation based on the causal work of the independent variable. Whereas *noise* refers to unsystematic variation or variation which is not the result of the independent variable. Unsystematic variation is the result of measurement error and we've seen that measurement error occurs in all types of measurement and statistics.\n\n## \n\nSo the changes observed in our dataset that are the result of systematic variation have to be *larger* then the differences we observe as the result of unsystematic variation for our statistical finding to be considered significant.\n\n## \n\nRemember that the null hypothesis assumes no differences between the groups, whereas the alternative hypothesis assumes the groups will be different because of the manipulation of the independent variable.\n\n## Levels of the Independent variable\n\nANOVA enables the comparison of more than two groups, which is often structured to analyze different levels of an independent variable. By levels we are referring to different amounts or quantities of the independent variable. For example, one group may be the control group, but then subsequent groups may have different quantities of the independent variable.\n\nHere is the dataset\n\n```{r, eval=TRUE}\nch15ds1\n```\n\nFirst let's look at the independent variable, which is attendance at preschool.\n\nIV = Preschool\n\nHere it is in R studio labeled as \"Group\"\n\n```{r}\nch15ds1$Group\n```\n\nNotice that there is 3 levels to this independent variable based on the amount of time spent in preschool per week: 5 hours, 10 hours, and 20 hours. Notice that there is no control group. Everyone is in preschool. So the hypothesis is really whether *more* time in preschool increases language development.\n\n### Creating Factors\n\nAn important first step for data analysis is to make sure the variables are in the correct format. We can use the `str` command to figure out the types of variables in the dataset.\n\n```{r}\nstr(ch15ds1)\n```\n\nLanguage.Score is an integer `int` or whole number, which makes sense for a measurement scale that is looking at language development.\n\nGroup is a character `chr`, which is fine for defining groups, but we would prefer it to be a factor so it could more easily distinguish the levels of the independent variable.\n\nSo let's change the variable type for group to a factor.\n\n```{r}\nch15ds1$Group <- factor(ch15ds1$Group, \n    levels = c(\"5 Hours\", \"10 Hours\", \"20 Hours\"))\n```\n\nAnd then check it\n\n```{r}\nstr(ch15ds1$Group)\n```\n\n### Are the means different?\n\nThe first question for the dataset is whether the means are different. More specifically, the mean level of language development should *increase* with an increase in hours spent at preschool.\n\n#### Mean difference between the groups\n\n```{r}\nch15ds1 |> \n  group_by(Group) |> \n  summarise(n = n(),\n            mean = mean(Language.Score))\n```\n\nSo the means are different and the language score increases with hours spent in preschool. Now it needs to be determined if the differences between the means are statistically significant. This is where we need the *ANOVA* or *F* Test.\n\n## Review\n\nRemember that the F test or ANOVA is based on comparing variation between the groups (signal) to variation within the groups (noise). So the equation is:\n\n$$\nF = \\frac{MS_{between}}{MS_{within}}\n$$\n\nHowever, there are some different steps we need to take to get to the two types of Mean Squares $MS$ for this formula.\n\nFor this usage of the ANOVA, the *total variability* $SS_T$ is partitioned (divided or separated) into 2 groups or sources. The variability between the groups $SS_{between}$ and the variability within the groups $SS_{within}$. Remember that variability between groups gives us evidence that the groups are different and if the variability is greater than the variability within the groups than our F value will be significant.\n\nHowever, the two sum of squares values ($SS_{within}$ & $SS_{between}$) need to be averaged based on the number of scores from which they were calculated in order to eliminate bias. In this case we'll use the degrees of freedom to accomplish this task $df$. Here is the formulas:\n\n$$df_{within} = N - 1$$\n\n$$df_{between}=k-1$$\n\n$N$ stands for the number of observations or participants we have in all the groups because it deals with individual variation. $k$ stands for the number of groups we have because it deals with group variation. Here is an overview of the entire formula.\n\n$$\n\\frac{SS_{between}/df_{between}}{SS_{within}/df_{within}} = \\frac{MS_{between}}{MS_{within}}= F\n$$\n\n### *F* Distribution\n\nHere's a look at the *F* distribution. Notice both the similaries and differences to the binomial and *t* and *z* distributions.\n\n```{r}\ndist_f(deg.f1 = 4, deg.f2 = 20, p = .05)\n```\n\nThe *F* distribution is also a family of curves based on the degrees of freedom. Notice that the distribution has a positive skew (more scores at the lower end of the distribution) and it also only had one tail rather than two tails. This is another indication that the *F* test can't determine the direction of difference between the groups, only if there is a difference between the groups.\n\n## Using R Studio to calculate the ANOVA\n\nIn another section, ANOVA was used to test a linear regression model. For that model a comparison was made between the improvement of the linear model in comparison to the grand mean $SS_{M}$ and the measurement error based on the residuals $SS_{R}$. There is a strong statistical relationship between regression and ANOVA and in fact ANOVA for groups can be understood as a part of the general linear model (GLM). The differences between the groups $SS_{between}$ can be understood as a line composed of the group means and compared to the grand mean $SS_M$. The greater the difference between this line and the grand mean, the greater the difference between the group means. $SS_{within}$ can be understood as the residuals for each observation and the grand mean $SS_R$. Everything else remains the same ($df$, $MS$, and $F$) when running the ANOVA in R Studio.\n\n#### Running the Code\n\nHere's the basic set up for running ANOVA\n\nObject \\<- aov(Dependent Variable \\~ Independent Variable, data = your dataset)\n\nSo in this case\n\n```{r}\nANOVA_1 <- aov(Language.Score~Group, data = ch15ds1)\n```\n\nFor ANOVA, the results are saved in an object, so we need to use `summary` to get the results.\n\n```{r}\nsummary(ANOVA_1)\n```\n\n\"Group\" is the independent variable so Sum Sq stands for the $SS_{between}$ or $SS_M$, whereas \"Residuals stands for the $SS_{within}$ or $SS_R$.\n\nThe *F* value is 8.799 and the significance or *p* value is 0.00114, so the results are significant.\n\n### Bar Graph of the Data\n\nStep 1 - create table of Descriptive Statistics\n\n```{r, eval=TRUE}\nlibrary(dplyr)\nPreschool_Descriptives <- ch15ds1 %>%\n  group_by(Group) %>%\n  summarize(n = n(),\n            mean = mean(Language.Score),\n            sd = sd(Language.Score),\n            se = sd / sqrt(n),\n            ci = qt(0.975, df = n - 1) * sd / sqrt(n))\n```\n\nCheck it out\n\n```{r, eval=TRUE}\nPreschool_Descriptives\n```\n\nNow graph it based on the descriptive statistics\n\n```{r, eval=TRUE}\nggplot(Preschool_Descriptives, \n       aes(x = Group, \n           y = mean)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin=mean-ci,\n                    ymax=mean+ci))\n```\n\nMake the graph look better.\n\n```{r}\nggplot(Preschool_Descriptives, \n       aes(x = Group,\n           y = mean)) +\n  theme_minimal() +\n  geom_bar(stat = \"identity\", fill=\"steelblue\") +\n  geom_errorbar(aes(ymin=mean-ci,\n                    ymax=mean+ci), width=.3, size=1) +\n  labs(title = \"Does Preschool Effect Language Development?\", \n       y=\"Mean Score on Language Test\", x=\"Number of Hours Spent in Preschool\") \n\n\n```\n\n### Effect Size\n\nFigure out the effect size - Eta squared The formula is SSbetween/SSTotal or SSbetween/SSbetween+SSResidual\n\n```{r, eval=TRUE}\n1133/(1133+1738)\n```\n\n### Conclusion\n\nWrite out conclusion\n\n> Number of hours in Preschool had a significant effect on language development, F(2, 27) = 8.799, p = 0.00114, 𝜂2 = 0.39.\n\nWhere is the difference? Need to use post hoc tests\n\n### TukeyHSD\n\nTukeyHSD will tell us where the differences are between the individual groups.\n\nRun TukeyHSD on saved ANOVA results\n\n```{r}\nTukeyHSD(ANOVA_1)\n```\n\nFinally, write out the whole conclusion.\n\n> TukeyHSD post hoc tests revealed that 20 hours a week of preschool (M=91.6, SE=1.96) resulted in significantly higher levels of language development in comparison to 5 hours (M=76.6, SE=3.78). This difference, -15 95% CI\\[-23.90, -6.10\\] was significant with an adjusted p = .0008.\n\n### \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"One-Way ANOVA.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","editor":"visual","theme":{"light":"minty","dark":"darkly"},"title":"One-Way ANOVA","author":"James Van Slyke"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}