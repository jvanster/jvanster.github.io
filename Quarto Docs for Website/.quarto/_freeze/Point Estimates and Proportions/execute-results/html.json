{
  "hash": "cfa5ea24ab86f949c31dd129ac605ed4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Point Estimates\"\nauthor: \"James Van Slyke\"\n---\n\n\n\n\n\nReference -\n\nDiez, D., OpenIntro Statistics\n\nChapter 5 - Foundations for Inference\n\n## Polling and Point estimates\n\nOne poll that is tracked often is the presidential approval ratings. Different polling agencies will conduct polls throughout the year to measure the country's assessment of how well the current president is doing running the country. Polling companies use samples to estimate presidential approval ratings, it would be next to impossible to poll the entire country every couple of weeks to determine the current approval ratings.\n\nSince we need to use samples to estimate the true current approval rating in the United States, the approval rating obtained from the sample is known as the *point estimate.* It's an estimate of the US population referred to as the *parameter of interest*. A *parameter* is a numeric value related to a population. Statistics attempts to quantify how well the parameter estimate *estimates* the parameter of interest. This is possible because there are certain properties that are usually present between a population and samples drawn from that population.\n\n## A stimulated approval rating\n\nOne of the great things that using R allows us to do is different types of simulations. We can simulate the behaviors and properties of a fictional population. For example, let's say that the current approval rating for a president is 60% approve and 40% disapprove. Thinking about this in terms of proportions .60 approve and .40 disapprove. So the true approval rating of the president in the population of US citizens would be 60%. Let's simulate this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Create a population of 340 million\n\npop_size <- 340000000\n#Create the approval/disapproval ratings\npossible_entries <- c(rep(\"approve\", 0.60 * pop_size),\n                      rep(\"disapprove\", 0.40 * pop_size))\n```\n:::\n\n\n\nThen we can take a random sample from this population\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Keep randomized sample the same\nset.seed(123)\n\n#Randomly Sample 1000 from the population\nsampled_entries <- sample(possible_entries, size = 1000)\n```\n:::\n\n\n\nThe random sample can be used to estimate the true population proportion. This is referred to as *p-hat* and the symbol looks like this $\\hat{p}$. This p-hat is our point estimate of the true approval rating in the population, even though in this case we know the real parameter.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(sampled_entries == \"approve\")/1000\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.604\n```\n\n\n:::\n:::\n\n\n\nNotice that this sample gave us an approval proportion of 0.611 or $\\hat{p}=0.611$ or 61%. The difference between the true parameter 60% and the p-hat is 1%. This is called the *error* of the estimate. As discussed throughout the course, all measurement and sampling involves a certain amount of error, but that error can be quantified to determine how confident we can be in our numbers.\n\n### Multiple Samples\n\nLet's look to see how our p-hat changes over several samples\n\nSample 2\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Sample\nsampled_entries <- sample(possible_entries, size = 1000)\n\n#p-hat\nsum(sampled_entries == \"approve\")/1000\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.603\n```\n\n\n:::\n:::\n\n\n\nSample 3\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Sample\nsampled_entries <- sample(possible_entries, size = 1000)\n\n#p-hat\nsum(sampled_entries == \"approve\")/1000\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.615\n```\n\n\n:::\n:::\n\n\n\nSample 4\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Sample\nsampled_entries <- sample(possible_entries, size = 1000)\n\n#p-hat\nsum(sampled_entries == \"approve\")/1000\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.563\n```\n\n\n:::\n:::\n\n\n\nNotice how $\\hat{p}$ varies slightly with every sample taken. This demonstrates the sampling error that exists between a sample and the population it is trying to estimate.\n\n### Larger numbers of samples\n\nWe can actually do better than just a few random samples from a population. Let's investigate what happens when we take a large number of samples and calculate the p-hat for each of the samples.\n\nTo do this, we can use the binomial distribution we used in an earlier lesson. Remember that a binomial distribution is used when there are two possibilities for a particular outcome. In this case the two outcomes are *approve* or *disapprove*. In this case we can use rbinom to randomly create a histogram based on sampling from a population with 60% approval and 40% disapproval.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Set the Parameters\nn_samples <- 10000   # Number of samples\nsample_size <- 1000  # Size of each sample\ntrue_p <- 0.6        # True proportion of \"approve\"\n\n#Use a randomly generated binomial distribution to simulate taking 10,000 samples with an n = 1000 from the population of the US\nsample_counts <- rbinom(n = n_samples, size = sample_size, prob = true_p)\n\n# Calculate the p-hat from the samples\np_hats <- sample_counts / sample_size\n\n# Create a datafrome of the p-hats\np_hat_df <- data.frame(p_hat = p_hats)\n\n# Create histogram\nphat_hist <- ggplot(p_hat_df, aes(x = p_hat)) +\n  geom_histogram(binwidth = 0.005, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Sampling Distribution of p̂\",\n       x = \"Sample Proportion (p̂)\",\n       y = \"Frequency\") +\n  theme_minimal()\nphat_hist\n```\n\n::: {.cell-output-display}\n![](Point-Estimates-and-Proportions_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Point-Estimates-and-Proportions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}